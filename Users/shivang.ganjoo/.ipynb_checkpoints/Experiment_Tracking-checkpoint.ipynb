{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "#IMPORTING THE AZURE TOOLS\n",
    "import azureml.core\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core import Workspace, Experiment\n",
    "# IMPORTING THE IRIS DATASET\n",
    "from sklearn.datasets import load_iris\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details of workspace\n",
    "subscription_id = \"743a779d-14da-46f0-82f6-d518e2f399a4\"\n",
    "resource_group = \"Norton-Internal\"\n",
    "workspace_name = \"shivang.ganjoo\"\n",
    "workspace_region = \"East US\"\n",
    "tenant_id = 'e4e34038-ea1f-4882-b6e8-ccd776459ca0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login via tenant_id\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=tenant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING DATA\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZING WORKSPACE\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZING EXPERIMENT \n",
    "experiment = Experiment(workspace=ws, name=\"demo-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING TRAIN_TEST_SPLIT TO GENERATE THE TRAINING AND TESTING SETS\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data,data.target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE WILL USE DECISION TREE CLASSIFIER AND OUR METRIC WILL BE ACCURACY SCORE \n",
    "# IMPORT JOBLIB TO STORE ML MODEL\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE WILL STORE THE ACCURACY AND MODEL FOR DIFFERENT VALUES OF MAX DEPTH.\n",
    "\n",
    "max_depth_list = [12,13,14,15,16,17,18,19,20,21]\n",
    "\n",
    "for max_depth in max_depth_list:\n",
    "    \n",
    "    # START AN EXPERIMENT LOG\n",
    "    run = experiment.start_logging()\n",
    "    \n",
    "    # STORE MAX_DEPTH VALUE\n",
    "    run.log(\"max_depth_value\", max_depth)\n",
    "    \n",
    "    # INITIALIZE MODEL\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    \n",
    "    # FIT MODEL TO TRAIN DATA\n",
    "    model.fit(X=X_train, y=y_train)\n",
    "    \n",
    "    # PREDICT VALUES FOR X_test \n",
    "    y_pred = model.predict(X=X_test)\n",
    "    \n",
    "    # CALCULATE ACCURACY_SCORE\n",
    "    score = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    \n",
    "    # STORE ACCURACY_SCORE\n",
    "    run.log(\"accuracy_score\", score)\n",
    "    \n",
    "    # SAVING THE MODEL IN A PICKLE FILE\n",
    "    model_name = \"model_max_depth_\" + str(max_depth) + \".pkl\"\n",
    "    filename = \"outputs/\" + model_name\n",
    "    joblib.dump(value=model, filename=filename)\n",
    "    \n",
    "    # STORING THE MODEL IN EXPERIMENT\n",
    "    run.upload_file(name=model_name, path_or_stream=filename)\n",
    "    \n",
    "    # COMPLETE RUN\n",
    "    run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>demo-experiment</td><td>Norton-ML</td><td><a href=\"https://ml.azure.com/experiments/demo-experiment?wsid=/subscriptions/743a779d-14da-46f0-82f6-d518e2f399a4/resourcegroups/Norton-Internal/workspaces/Norton-ML\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: demo-experiment,\n",
       "Workspace: Norton-ML)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth_value': 21, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 20, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 19, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 18, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 17, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 16, 'accuracy_score': 0.9666666666666667}\n",
      "{'accuracy_score': 0.9666666666666667, 'max_depth_value': 15}\n",
      "{'max_depth_value': 14, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 13, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 12, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 11, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 10, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 9, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 8, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 7, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 6, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 5, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 4, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 3, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 2, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 9, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 8, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 7, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 6, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 5, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 4, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 3, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 2, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 9, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 8, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 7, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 6, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 5, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 4, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 3, 'accuracy_score': 0.9666666666666667}\n",
      "{'max_depth_value': 2, 'accuracy_score': 0.9666666666666667}\n",
      "Best run_id: 62323057-0f7d-4c62-8463-9a124b2fdc0f\n",
      "Best run_id rmse: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "minimum_acc_runid = None\n",
    "minimum_acc = None\n",
    "\n",
    "for run in experiment.get_runs():\n",
    "#     print(run)\n",
    "    run_metrics = run.get_metrics()\n",
    "#     print(run_metrics)\n",
    "    \n",
    "    run_details = run.get_details()\n",
    "#     print(run_details)\n",
    "#     print('\\n')\n",
    "    # each logged metric becomes a key in this returned dict\n",
    "    if 'accuracy_score' in run_metrics:\n",
    "        print(run_metrics)\n",
    "        run_acc = run_metrics[\"accuracy_score\"]\n",
    "        run_id = run_details[\"runId\"]\n",
    "\n",
    "        if minimum_acc is None:\n",
    "            minimum_acc = run_acc\n",
    "            minimum_acc_runid = run_id\n",
    "        else:\n",
    "            if run_acc < minimum_acc:\n",
    "                minimum_acc = run_acc\n",
    "                minimum_acc_runid = run_id\n",
    "\n",
    "print(\"Best run_id: \" + minimum_acc_runid)\n",
    "print(\"Best run_id rmse: \" + str(minimum_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you\n"
     ]
    }
   ],
   "source": [
    "print(\"Thank you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
